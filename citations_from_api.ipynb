{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saifullahAnsari0001/assignment/blob/main/citations_from_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Identifying Citations from API Responses**"
      ],
      "metadata": {
        "id": "_j1IS3HFqGGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from sentence_transformers import SentenceTransformer, util"
      ],
      "metadata": {
        "id": "Vj6MTGCPwRi6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Begin by testing code on a sample dataset to verify its correctness. Once confirmed satisfactory results, extend the logic to process the entire dataset. This incremental approach ensures accuracy and reliability throughout the process.**"
      ],
      "metadata": {
        "id": "ZL31dAi8DZMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_model():\n",
        "#     \"\"\"Load the Sentence Transformer model.\"\"\"\n",
        "#     try:\n",
        "#         model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "#     except Exception as e:\n",
        "#         print(\"Error loading the model:\", e)\n",
        "#         return None\n",
        "#     return model\n",
        "\n",
        "# def identify_citations(response_text, sources, model, threshold):\n",
        "#     \"\"\"Identify citations based on the similarity between response text and sources.\"\"\"\n",
        "#     citations = []\n",
        "\n",
        "#     # Encode the response text and source contexts to obtain embeddings\n",
        "#     response_embedding = model.encode(response_text, convert_to_tensor=True)\n",
        "#     context_embeddings = model.encode([source['context'] for source in sources], convert_to_tensor=True)\n",
        "\n",
        "#     # Calculate cosine similarity between the response and source embeddings\n",
        "#     similarities = util.pytorch_cos_sim(response_embedding, context_embeddings)\n",
        "\n",
        "#     # Extract citations for contexts with similarity above the threshold\n",
        "#     for idx, sim in enumerate(similarities[0]):\n",
        "#         if sim.item() > threshold:\n",
        "#             citations.append({\n",
        "#                 'id': sources[idx]['id'],\n",
        "#                 'link': sources[idx]['link']\n",
        "#             })\n",
        "\n",
        "#     return citations\n",
        "\n",
        "# # Example usage\n",
        "# def main():\n",
        "#     # Load the pre-trained model\n",
        "#     model = load_model()\n",
        "#     if model is None:\n",
        "#         return\n",
        "\n",
        "#     # Example response text\n",
        "#     response_text = \"Yes, we offer online delivery services through major platforms like Swiggy and Zomato. You can also reserve a table directly from our website if you are planning to have breakfast!\"\n",
        "\n",
        "#     # Example sources\n",
        "#     sources = [\n",
        "#         {\n",
        "#             \"id\": \"71\",\n",
        "#             \"context\": \"Order online Thank you for your trust in us! We are available on all major platforms like zomato, swiggy. You can also order directly from our website\",\n",
        "#             \"link\": \"https://orders.brikoven.com\"\n",
        "#         },\n",
        "#         {\n",
        "#             \"id\": \"75\",\n",
        "#             \"context\": \"Do you give franchise if the brand No, we currently don't offer franchise opportunities for BrikOven! Although do feel free to drop in an email at theteam@brikoven.com so we can get in touch with you at a later stage if we do decide to give out franchisees'\",\n",
        "#             \"link\": \"\"\n",
        "#         },\n",
        "#         {\n",
        "#             \"id\": \"8\",\n",
        "#             \"context\": \"Breakfast Reservations\\r For Breakfast, we recommend making reservations in advance. Reservation is only available through our website\",\n",
        "#             \"link\": \"https://www.brikoven.com/reservations\"\n",
        "#         }\n",
        "#     ]\n",
        "\n",
        "#     # Define the similarity threshold\n",
        "#     threshold = 0.5\n",
        "\n",
        "#     # Identify citations\n",
        "#     citations = identify_citations(response_text, sources, model, threshold)\n",
        "\n",
        "#     # Print the identified citations\n",
        "#     print(\"Citations:\", citations)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "id": "cwYwkJwFlcEW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ***After confirming the effectiveness of the code on a sample dataset, extend the same logic to process the entire dataset. ***"
      ],
      "metadata": {
        "id": "vYgZ9uZCoiYT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Begin by fetching data from the specified API endpoints and storing it locally. This initial step sets the foundation for further processing and analysis.**"
      ],
      "metadata": {
        "id": "D5OFLyW3myeK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "oeI42HAwoz8S"
      },
      "outputs": [],
      "source": [
        "# def fetch_data(api_url):\n",
        "#     all_data = []\n",
        "#     page = 1\n",
        "\n",
        "#     try:\n",
        "#         while True:\n",
        "#             response = requests.get(api_url, params={'page': page})\n",
        "#             response.raise_for_status()\n",
        "#             data = response.json()\n",
        "\n",
        "#             if 'data' not in data or 'data' not in data.get('data', {}):\n",
        "#                 break\n",
        "\n",
        "#             all_data.extend(data['data']['data'])\n",
        "\n",
        "#             if not data['data'].get('next_page_url'):\n",
        "#                 break\n",
        "#             page += 1\n",
        "#     except requests.RequestException as e:\n",
        "#         print(\"Error fetching data:\", e)\n",
        "#         return []\n",
        "\n",
        "#     return all_data\n",
        "\n",
        "\n",
        "# api_endpoint = \"https://devapi.beyondchats.com/api/get_message_with_sources\"\n",
        "\n",
        "# all_data = fetch_data(api_endpoint)\n",
        "\n",
        "# print(\"Total number of items fetched:\", len(all_data))\n",
        "\n",
        "# with open('fetched_data.json', 'w') as f:\n",
        "#     json.dump(all_data, f, indent=2)\n",
        "\n",
        "# print(\"Data has been saved to fetched_data.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Yv-qEd1P8txO"
      },
      "outputs": [],
      "source": [
        "# with open('fetched_data.json', 'r') as f:\n",
        "#     saved_data = json.load(f)\n",
        "\n",
        "# print(json.dumps(saved_data, indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Now, aim to determine if each response corresponds to any of the provided sources across the entire dataset. This step involves comparing response texts with the context of each source to identify potential matches**"
      ],
      "metadata": {
        "id": "a71cS-MjxvRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def load_model():\n",
        "#     \"\"\"Load the Sentence Transformer model.\"\"\"\n",
        "#     try:\n",
        "#         model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
        "#     except Exception as e:\n",
        "#         print(\"Error loading the model:\", e)\n",
        "#         return None\n",
        "#     return model\n",
        "\n",
        "# def identify_citations(response_text, sources, model, threshold=0.5):\n",
        "#     \"\"\"Identify citations based on the similarity between response text and sources.\"\"\"\n",
        "#     citations = []\n",
        "\n",
        "#     # Encode the response text and source contexts to obtain embeddings\n",
        "#     response_embedding = model.encode(response_text, convert_to_tensor=True)\n",
        "#     context_embeddings = model.encode([source['context'] for source in sources], convert_to_tensor=True)\n",
        "\n",
        "#     # Calculate cosine similarity between the response and source embeddings\n",
        "#     similarities = util.pytorch_cos_sim(response_embedding, context_embeddings)\n",
        "\n",
        "#     # Extract citations for contexts with similarity above the threshold\n",
        "#     for idx, sim in enumerate(similarities[0]):\n",
        "#         if sim.item() > threshold:\n",
        "#             citations.append({\n",
        "#                 'id': sources[idx]['id'],\n",
        "#                 'link': sources[idx]['link']\n",
        "#             })\n",
        "\n",
        "#     return citations\n",
        "\n",
        "# def process_data(data, model, threshold=0.6):\n",
        "#     \"\"\"Process data and identify citations for each response.\"\"\"\n",
        "#     processed_data = []\n",
        "\n",
        "#     for item in data:\n",
        "#         response_text = item.get('response', '')\n",
        "#         sources = item.get('source', [])\n",
        "\n",
        "#         # Identify citations for the response\n",
        "#         citations = identify_citations(response_text, sources, model, threshold)\n",
        "\n",
        "#         # Store the processed item with its ID and citations\n",
        "#         processed_item = {'id': item.get('id'), 'citations': citations}\n",
        "#         processed_data.append(processed_item)\n",
        "\n",
        "#     return processed_data\n",
        "\n",
        "# def main():\n",
        "#     # Load data from the JSON file\n",
        "#     try:\n",
        "#         with open('fetched_data.json', 'r') as f:\n",
        "#             fetched_data = json.load(f)\n",
        "#     except FileNotFoundError as e:\n",
        "#         print(\"Error loading the JSON file:\", e)\n",
        "#         return\n",
        "\n",
        "#     # Load the pre-trained model\n",
        "#     model = load_model()\n",
        "#     if model is None:\n",
        "#         return\n",
        "\n",
        "#     # Define the similarity threshold\n",
        "#     threshold = 0.5\n",
        "\n",
        "#     # Process the data and identify citations\n",
        "#     processed_data = process_data(fetched_data, model, threshold)\n",
        "\n",
        "#     # Print the processed data\n",
        "#     for item in processed_data:\n",
        "#         print(json.dumps({'id': item['id'], 'citations': item['citations']}, indent=4))\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()\n"
      ],
      "metadata": {
        "id": "tppd2oCutWoI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WtMd7s-swD7d"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrMXFLlX6GOdYJrHzDhW7w",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}